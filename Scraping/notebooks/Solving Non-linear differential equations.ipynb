{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Operator Imports\n",
    "from qiskit import QuantumRegister, QuantumCircuit\n",
    "from qiskit.opflow import X, Y, Z, I, Zero, StateFn, CircuitStateFn, SummedOp, ListOp, PauliExpectation, PauliSumOp\n",
    "from qiskit.opflow.gradients import Gradient, Hessian\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit_machine_learning.neural_networks import OpflowQNN\n",
    "from qiskit.aqua.components.optimizers import ADAM, AQGD, COBYLA\n",
    "\n",
    "# imports to plot stuff\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumODESolver(object):\n",
    "    \"\"\"\n",
    "    Main Class for the ODE solver using Hybrid Classical-Quantum\n",
    "    neural network. Instantiate this class to use the solver.\n",
    "    \n",
    "    Implementation of the following paper: arXiv:2011.10395v2 in Qiskit.\n",
    "    \n",
    "    >> Developed as part of Qiskit Mentorship Program 2021 (Project #32:\n",
    "    Solving Navier-Stokes equations using Qiskit for Water Management.) <<\n",
    "    \n",
    "    Init Parameters\n",
    "    ---------------\n",
    "    \n",
    "    num_qubits : Number of qubits in the quantum register of the quantum model \n",
    "                 circuit.\n",
    "    \n",
    "    variational_layers : Number of variational layers in the model circuit.\n",
    "    \n",
    "    encoder_layers : Number of encoder layers in the model circuit.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, num_qubits = 1, variational_layers = 1, encoder_layers = 1):\n",
    "        self.num_qubits = num_qubits\n",
    "        self.encoder_layers = encoder_layers\n",
    "        self.variational_layers = variational_layers\n",
    "        self.encoder_symbols = []\n",
    "        self.unitary_symbols = []\n",
    "        self.model_circuit = QuantumCircuit(self.num_qubits)\n",
    "        self.model = None\n",
    "        self.measure_op = None\n",
    "        self.gradient_op = None\n",
    "        # Construct encoder block of the model\n",
    "        self.construct_encoder()\n",
    "        \n",
    "        # Construct variational block of the model\n",
    "        #self.construct_variational_ansatz()\n",
    "        \n",
    "        # Get measurement observable\n",
    "        self.get_measurement_observable()\n",
    "        \n",
    "        # Forming combined model\n",
    "        self.compile_model()\n",
    "        \n",
    "        print(\"Model compiled...........................\")\n",
    "        \n",
    "        # Initialize unitary parameters\n",
    "        self.unitary_params = np.random.random(size = (len(self.unitary_symbols), ))\n",
    "        \n",
    "        # Initialize gradient op of the model circuit\n",
    "        self.gradient_op = Gradient(grad_method = 'fin_diff').convert(operator = self.model, params = (self.encoder_symbols))\n",
    "        \n",
    "        \n",
    "    def construct_encoder(self):\n",
    "        \"\"\"\n",
    "        Apply Quantum Feature map (Chebyshev sparse encoding) to the final \n",
    "        model circuit. Feel free to change the code below to implement other\n",
    "        quantum feature maps.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        None\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        None\n",
    "        \n",
    "        \"\"\"\n",
    "        self.encoder_block = QuantumCircuit(self.num_qubits, name = 'Encoder Block')\n",
    "        x = Parameter('x')\n",
    "        self.encoder_symbols.append(x)\n",
    "        for i in range(self.num_qubits):\n",
    "            self.encoder_block.ry(2 * (i+1) * np.arccos(x), i)\n",
    "        #print(\"Encoder Block------------------------------------\")\n",
    "        #display(self.encoder_block.draw(output = 'mpl'))\n",
    "        return \n",
    "        \n",
    "        \n",
    "    def construct_variational_ansatz(self, layer):\n",
    "        \"\"\"\n",
    "        Apply Hardware-efficient ansatz as the variational block in the\n",
    "        final model circuit. Feel free to change the code below to\n",
    "        implement different architectures for the variational part of\n",
    "        the model circuit.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        layer : Layer number of the variational block to be created. To\n",
    "                differentiate between the subsequent layers of the same\n",
    "                variational block, if the same block is repeated. If layer\n",
    "                is same for two blocks, then the two blocks will \n",
    "                have the same values for the unitary parameters.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        None\n",
    "        \n",
    "        \"\"\"\n",
    "        self.variational_block = QuantumCircuit(self.num_qubits, name = 'Variational Block ' + str(layer + 1))\n",
    "        # First, we apply Wall of unitaries\n",
    "        for i in range(self.num_qubits):\n",
    "            theta_z0 = Parameter('theta_z0' + str(i) + str(layer))\n",
    "            self.unitary_symbols.append(theta_z0)\n",
    "            theta_x = Parameter('theta_x' + str(i) + str(layer))\n",
    "            self.unitary_symbols.append(theta_x)\n",
    "            theta_z1 = Parameter('theta_z1'+ str(i) + str(layer))\n",
    "            self.unitary_symbols.append(theta_z1)\n",
    "            self.variational_block.rz(theta_z0, i)\n",
    "            self.variational_block.rx(theta_x, i)\n",
    "            self.variational_block.rz(theta_z1, i)\n",
    "\n",
    "        # Next, we apply Entanglement wall (in a cyclic fashion, joining immediate neighbours)\n",
    "        for i in range(1, self.num_qubits):\n",
    "            self.variational_block.cx(i - 1, i)\n",
    "        #if num_qubits > 1:\n",
    "        #    self.variational_block.cx(self.num_qubits-1, 0)\n",
    "        #print(\"Variational block--------------------------------\")\n",
    "        #display(self.variational_block.draw(output = 'mpl'))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def get_measurement_observable(self):\n",
    "        \"\"\"\n",
    "        Construct operator for measurement of expectation value\n",
    "        of the final model circuit.\n",
    "        Note, can be any quantum circuit, but for now considering\n",
    "        only the total magnetic spin of the quantum register. Feel free\n",
    "        to change this functin as per design choice.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        None\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        None\n",
    "        \n",
    "        \"\"\"\n",
    "        self.measure_op = None\n",
    "        for i in range(self.num_qubits):\n",
    "            block = None\n",
    "            for j in range(self.num_qubits):\n",
    "                if j == i:\n",
    "                    if block is None:\n",
    "                        block = Z\n",
    "                    else:\n",
    "                        block = Z ^ block\n",
    "                else:\n",
    "                    if block is None:\n",
    "                        block = I\n",
    "                    else:\n",
    "                        block = I ^ block\n",
    "            if self.measure_op is None:\n",
    "                self.measure_op = block\n",
    "            else:\n",
    "                self.measure_op = self.measure_op + block\n",
    "        #print(\"Measurement op \\n, \", self.measure_op)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def compile_model(self):\n",
    "        \"\"\"\n",
    "        Compile (concatenate) the variational blocks and encoder blocks to get \n",
    "        the final model circuit expectation operator. \n",
    "        Feel free to change the code of this function to change the overall architecture \n",
    "        of the quantum model circuit (i.e, whether or not to repeat variational\n",
    "        or encoder blocks (\"Data re-uploading\") etc.)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        None\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        None\n",
    "        \n",
    "        \"\"\"\n",
    "        measure = self.convert_to_statefn(self.measure_op, is_measurement = True)\n",
    "        for i in range(self.encoder_layers):\n",
    "            if i == 0:\n",
    "                self.construct_variational_ansatz(layer = i)\n",
    "            self.model_circuit.append(self.variational_block, range(self.num_qubits))\n",
    "            self.model_circuit.append(self.encoder_block, range(self.num_qubits))\n",
    "        self.construct_variational_ansatz(layer = self.encoder_layers)\n",
    "        self.model_circuit.append(self.variational_block, range(self.num_qubits))\n",
    "        self.model = PauliExpectation().convert(measure @ CircuitStateFn(self.model_circuit))\n",
    "        return\n",
    "        \n",
    "        \n",
    "    def convert_to_statefn(self, obj, is_measurement = False):\n",
    "        \"\"\"\n",
    "        Convert obj to StateFn, throws exception if cannot convert.\n",
    "        \n",
    "        \"\"\"\n",
    "        try:\n",
    "            if is_measurement:\n",
    "                return ~StateFn(obj)\n",
    "            else:\n",
    "                return StateFn(obj)\n",
    "        except Exception as err:\n",
    "            print(\"Cannot convert object of type {} to StateFn \".format(type(obj)))\n",
    "            print(\"Complete error log is as follows-------------\")\n",
    "            print(\">> {} <<\".format(err))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def resolve_parameters(self, data, param_values):\n",
    "        \"\"\"\n",
    "        Resolves the parameter values for free parameters in the final\n",
    "        model circuit.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        data : Classical data that goes into the encoder block.\n",
    "               \n",
    "        param_values : Parameter values for the free parameter in the unitary block.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        A dictionary that maps each free parameter in the final model circuit\n",
    "        (encoder blocks + unitary blocks) to corresponding value. The output \n",
    "        of this function can directly be used to bind parameter values in the\n",
    "        model circuit operator (if successful).\n",
    "        \n",
    "        \"\"\"\n",
    "        param_dict = {}\n",
    "        data = np.array(data)\n",
    "        if len(param_values.shape) == 1:\n",
    "            param_values = list(param_values)\n",
    "        else:\n",
    "            param_values = list(param_values.flatten())\n",
    "        \n",
    "        data_size = data.shape[0]\n",
    "        model_param_values = []\n",
    "        model_param_vars = []\n",
    "        if data.shape[-1] != len(self.encoder_symbols) and len(data.shape) != len(self.encoder_symbols):\n",
    "            print(\"Dimensionality of data does not match the number of free parameters for encoding data in the model circuit\")\n",
    "            return\n",
    "        if len(param_values) != len(self.unitary_symbols):\n",
    "            print(len(self.unitary_symbols))\n",
    "            print(len(param_values))\n",
    "            print(\"Number of param values supplied not equal to number of free parameters in the unitary blocks of the model circuit\")\n",
    "            return\n",
    "        for var in self.encoder_symbols:\n",
    "            model_param_vars.append(var)\n",
    "        if len(data.shape) == 1:\n",
    "            model_param_values.append(list(data))\n",
    "        else:\n",
    "            for p in data:\n",
    "                model_param_values.append(list(p))\n",
    "        #print(\"After resolving encoder params : \", model_param_values)\n",
    "        for param in param_values:\n",
    "            model_param_values.append([param] * data_size)\n",
    "\n",
    "        #print(\"After resolving unitary params : \", model_param_values)\n",
    "        for var in self.unitary_symbols:\n",
    "            model_param_vars.append(var) \n",
    "        param_dict = dict(zip(model_param_vars, model_param_values))\n",
    "        if len(param_dict.keys()) != len(self.encoder_symbols) + len(self.unitary_symbols):\n",
    "            print(\"Resolving of parameters failed, check the number of parameter values passes for resolving !!\")\n",
    "            print(\"Number of free parameters : {}\".format(len(self.encoder_symbols) + len(self.unitary_symbols)))\n",
    "            print(\"Number of resolved params : {}\".format(len(param_dict.keys())))\n",
    "            print(param_dict)\n",
    "            return\n",
    "        return param_dict\n",
    "    \n",
    "    \n",
    "    def predict(self, data, param_values = None, is_training = False, verbose = False):\n",
    "        \"\"\"\n",
    "        Get expectation value and gradient at each data point from the model circuit.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        data: Classical Grid points which is to be encoded as input in the quantum model.\n",
    "        \n",
    "        param_values : (Optional) Parameter values for the unitary block parameters at which the \n",
    "                       model output should be evaluated. If not provided by user, it fills this variable\n",
    "                       with already stored parameter values in the object of QuantumODESolver class.\n",
    "        \n",
    "        is_training : Boolean flag to denote whether the call to this function is being made at the time\n",
    "                      of training. If True, then the function outputs both solution of the differential equation\n",
    "                      at grid points x and the corresponding gradients of the solution function at those points.\n",
    "                      If False, it just outputs the evaulated solution at grid points. \n",
    "        \n",
    "        verbose : (Optional) To print every predict function call output in each iteration of optimizer. Useful\n",
    "                  to check how many calls the optimizer makes to the predict function.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        Either two lists of solution values at grid points x and corresponding gradients at \n",
    "        those points, or simply a list of solution values at grid points x.\n",
    "        \n",
    "        \"\"\"\n",
    "        batch_size = 1\n",
    "        exp_values = []\n",
    "        grad_values = []\n",
    "        if param_values is None:\n",
    "            param_values = self.unitary_params\n",
    "        param_values = np.array(param_values).flatten()\n",
    "        if len(param_values) == len(self.unitary_params):\n",
    "            param_values = param_values[np.newaxis, :]  \n",
    "        else:\n",
    "            if len(param_values.flatten()) % len(self.unitary_params) != 0:\n",
    "                print(\"Cannot reshape the parameter values provided into shape  = ({}, )\".format(len(self.unitary_params)))\n",
    "                sys.exit()\n",
    "            batch_size = int(len(param_values.flatten()) / len(self.unitary_params))\n",
    "            param_values = np.reshape(param_values, newshape = (batch_size, len(self.unitary_params)))\n",
    "                             \n",
    "        # Predicting for each batch of parameters supplied\n",
    "        for batch in range(batch_size):\n",
    "            batch_exp_value = None\n",
    "            batch_grad_value = None\n",
    "            if verbose:\n",
    "                print(\"Predicting for batch {} / {}\".format((batch + 1), batch_size), end = '\\r')\n",
    "            batch_param_values = param_values[batch]\n",
    "            param_dict = self.resolve_parameters(data, batch_param_values)\n",
    "            if param_dict is None:\n",
    "                print(\"Prediction failed for batch {} / {}...\".format((batch + 1), batch_size))\n",
    "                sys.exit()\n",
    "            batch_exp_value = self.model.bind_parameters(param_dict)\n",
    "            batch_exp_value = np.real(batch_exp_value.eval()).flatten() / self.num_qubits\n",
    "            exp_values.append(list(batch_exp_value))\n",
    "            if is_training:\n",
    "                batch_grad_value = np.real(self.gradient_op.bind_parameters(param_dict).eval()).flatten()\n",
    "                grad_values.append(list(batch_grad_value))\n",
    "        if is_training:\n",
    "            return exp_values, grad_values\n",
    "        else:\n",
    "            return exp_values\n",
    "    \n",
    "    \n",
    "    def solution(self, x, param_values = None, is_training = False, verbose = False):\n",
    "        \"\"\"\n",
    "        Internally calls the predict function and outputs the value of\n",
    "        solution for given array points in the arguments. Also takes\n",
    "        care of the floating boundary condition.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        x : Numpy array of data grid points at which the solution (function that solves \n",
    "            the required differential equation) needs to be evaluated.\n",
    "        \n",
    "        param_values : (Optional) Parameter values for the unitary block parameters at which the \n",
    "                       model output should be evaluated. If not provided by user, it fills this variable\n",
    "                       with already stored parameter values in the object of QuantumODESolver class.\n",
    "        \n",
    "        is_training : Boolean flag to denote whether the call to this function is being made at the time\n",
    "                      of training. If True, then the function outputs both solution of the differential equation\n",
    "                      at grid points x and the corresponding gradients of the solution function at those points.\n",
    "                      If False, it just outputs the evaulated solution at grid points. \n",
    "        \n",
    "        verbose : (Optional) To print every predict function call output in each iteration of optimizer. Useful\n",
    "                  to check how many calls the optimizer makes to the predict function.\n",
    "                  \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        Either two lists of solution values at grid points x and corresponding gradients at \n",
    "        those points, or simply a list of solution values at grid points x.\n",
    "        \n",
    "        \"\"\"\n",
    "        u, du_dx = self.predict(x, param_values, is_training = True, verbose = verbose)\n",
    "        \n",
    "        # Floating boundary condition\n",
    "        bc = self.predict(np.array([0.0]), param_values, verbose = verbose)\n",
    "        # Reshaping arrays\n",
    "        u  = np.array(u)\n",
    "        bc = np.array(bc)\n",
    "        du_dx = np.array(du_dx)\n",
    "        u = np.reshape(u, newshape = (u.shape[1], u.shape[0]))\n",
    "        bc = np.reshape(bc, newshape = (bc.shape[1], bc.shape[0]))\n",
    "        du_dx = np.reshape(du_dx, newshape = (du_dx.shape[1], du_dx.shape[0]))\n",
    "        \n",
    "        # With floating boundary condition, the value of function itself is defined in such a way\n",
    "        # that the boundary condition is always satisfied irrespective of the model (quantum circuit's) output.\n",
    "        u = np.array([1] * u.shape[1])  - bc + u\n",
    "        \n",
    "        if is_training:\n",
    "            return u, du_dx\n",
    "        else:\n",
    "            return u\n",
    "        \n",
    "    \n",
    "    def fit(self, x, y = None, epochs = 20, batch_size = 5, lr = 0.05, optimizer_maxiter = 5, verbose = False):\n",
    "        \"\"\"\n",
    "        \n",
    "        Fit function for the quantum model used to train the model. Feel free to change the loss function\n",
    "        method inside as per the differential equation required to solve.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        \n",
    "        x : Numpy array of data grid points at which the model is fitted.\n",
    "        \n",
    "        y : (Optional) values which can be further used to define boundary conditions or \n",
    "            initial conditions. Default to None.\n",
    "            \n",
    "        epochs : Number of epochs for which the model should be trained.\n",
    "        \n",
    "        batch_size : Number of data grid points to be taken in a single batch of training.\n",
    "                     Note, that the update to the parameter happens for each batch rather \n",
    "                     than at the end of epoch.\n",
    "        \n",
    "        lr : learning rate used for the ADAM optimizer. Not required if some other optimizer is chosen.\n",
    "        \n",
    "        optimizer_maxiter : Max iterations for which a single batch of training data should be used\n",
    "                            to update the parameter values. This parameter is passed to the optimizer (currently\n",
    "                            implemented for ADAM).\n",
    "        \n",
    "        verbose : (Optional) To print every loss function call output in each iteration of optimizer. Useful\n",
    "                  to check how many calls the optimizer makes to the loss function.\n",
    "                  \n",
    "        Returns\n",
    "        -------\n",
    "        \n",
    "        List of parameter values after the model is trained.\n",
    "                  \n",
    "        \"\"\"\n",
    "        def loss_function(param_values):\n",
    "            # get function value (f(x)) and gradients at points specified (array 'x' above)\n",
    "            u, du_dx = self.solution(curr_batch, param_values, is_training = True, verbose = verbose)\n",
    "            \n",
    "            # Change the line below as per the differential equation required to solve\n",
    "            # Following differential equation is taken from arXiv:2011.10395v2\n",
    "            loss = np.mean(np.log((du_dx + 20 * u *(0.1 + np.tan(20 * u))) ** 2), axis = 0)\n",
    "            return loss\n",
    "        \n",
    "        epoch = 0\n",
    "        batch_start_idx = 0\n",
    "        curr_batch = x\n",
    "        epoch_end = False\n",
    "        \n",
    "        print(\"Initial Loss : {}\".format(loss_function(param_values = None)))\n",
    "        print(\"Initial unitary params : {}\".format(self.unitary_params))\n",
    "        print(\"Initial learning rate : {}\".format(lr))\n",
    "        print(\"Training Begins...........................................................................................\")\n",
    "        while(epoch < epochs):\n",
    "            epoch_loss = 0.0\n",
    "            batch_start_idx = 0\n",
    "            curr_batch = None\n",
    "            epoch_end = False\n",
    "            while(not epoch_end):\n",
    "                print(\"Training for Batch {} / {}\".format(int(batch_start_idx / batch_size) + 1, int(np.ceil(len(x) / batch_size))), end = '\\r')\n",
    "                curr_batch = x[batch_start_idx : min(batch_start_idx + batch_size, len(x))]\n",
    "                self.unitary_params, epoch_loss , _ = ADAM(maxiter = optimizer_maxiter, lr = lr).optimize(len(self.unitary_symbols), loss_function, initial_point = self.unitary_params)\n",
    "                if min(batch_start_idx + batch_size, len(x)) == len(x):\n",
    "                    epoch_end = True\n",
    "                else:\n",
    "                    batch_start_idx += batch_size\n",
    "            curr_batch = x\n",
    "            print(\"Epoch : {}, Current Loss : {}\".format((epoch + 1), loss_function(param_values = None)))\n",
    "            print(\"Updated param values: \", self.unitary_params)\n",
    "            print(\"Current learning rate : {}\".format(lr))\n",
    "            print(\"-------------------------------------------------------------------------------------------------------\")\n",
    "            epoch += 1\n",
    "            #lr = (epoch + 1) * (1e-02 - 1e-04)/(epochs)\n",
    "        return self.unitary_params\n",
    "        \n",
    "            \n",
    "    def __call__(self):\n",
    "        print(\"This model is constructed for-----\")\n",
    "        print(\"Number of qubits : {}\".format(self.num_qubits))\n",
    "        print(\"Number of layers (depth) : For encoder block - {}, For variational block - {}\".format(self.encoder_layers, self.variational_layers))\n",
    "        print(\"Structure of encoder block-----\")\n",
    "        display(self.encoder_block.draw(output = 'mpl'))\n",
    "        print(\"Structure of variational block-----\")\n",
    "        display(self.variational_block.draw(output = 'mpl'))\n",
    "        print(\"Complete model circuit looks like : \")\n",
    "        display(self.model_circuit.draw(output = 'mpl'))\n",
    "        print(\"Number of variational parameters : {}\".format(len(self.unitary_symbols)))\n",
    "        print(\"Number of encoder parameters : {}\".format(len(self.encoder_symbols)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the solver architecture\n",
    "num_qubits = 6\n",
    "enc_layers = 5\n",
    "var_layers = 1\n",
    "# Creating data grid points\n",
    "X = np.linspace(0, 0.9, 20)\n",
    "# Instantiating the solver\n",
    "solver = QuantumODESolver(num_qubits, var_layers, enc_layers)\n",
    "# Summary of model architecture\n",
    "solver()\n",
    "# Training the solver\n",
    "solver.fit(X, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the solver\n",
    "X_test = np.linspace(0, 0.9, 30)\n",
    "predicted = solver.solution(X_test)\n",
    "plt.plot(X_test, np.exp(-20 * 0.1 * X_test) * np.cos(20 * X_test), c = 'yellow')\n",
    "plt.plot(X_test, predicted, c = 'blue')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
